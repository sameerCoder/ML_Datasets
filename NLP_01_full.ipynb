{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_01_full.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXE+Lhdj10owsON8LlbbeT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJsafA0HV-k_"
      },
      "source": [
        "import nltk\n",
        "import nltk.corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM9PSaUiXM5x",
        "outputId": "dae15b1f-268c-4a01-9fd2-2c3d1aae5ac5"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlzOjHJXWf4Y"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeDDGLT5WnPE"
      },
      "source": [
        "sen1=\"This is a NLP class and learn the topic very nicely and become a succesfully\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGy3P4EdW4Ne",
        "outputId": "906a4f48-00c7-447b-e75f-c7a0290d5d4b"
      },
      "source": [
        "sen1_token=word_tokenize(sen1)\n",
        "sen1_token"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'NLP',\n",
              " 'class',\n",
              " 'and',\n",
              " 'learn',\n",
              " 'the',\n",
              " 'topic',\n",
              " 'very',\n",
              " 'nicely',\n",
              " 'and',\n",
              " 'become',\n",
              " 'a',\n",
              " 'succesfully']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iRtGu7RXEHx",
        "outputId": "5b63a19d-df34-420f-ec12-65a07908901e"
      },
      "source": [
        "type(sen1_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGvuLMLpXWrV",
        "outputId": "5487ffe0-5bce-4469-aa05-0bc9785bd643"
      },
      "source": [
        "# occurance\n",
        "from nltk.probability import FreqDist\n",
        "freq1=FreqDist()\n",
        "\n",
        "for i in sen1_token:\n",
        "  freq1[i]=freq1[i]+1\n",
        "\n",
        "freq1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'NLP': 1,\n",
              "          'This': 1,\n",
              "          'a': 2,\n",
              "          'and': 2,\n",
              "          'become': 1,\n",
              "          'class': 1,\n",
              "          'is': 1,\n",
              "          'learn': 1,\n",
              "          'nicely': 1,\n",
              "          'succesfully': 1,\n",
              "          'the': 1,\n",
              "          'topic': 1,\n",
              "          'very': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8wMMgMyYsxp",
        "outputId": "493ab1f8-800c-449a-a5c6-a139b580c26b"
      },
      "source": [
        "top_5=freq1.most_common(5)\n",
        "top_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2), ('and', 2), ('This', 1), ('is', 1), ('NLP', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To find the frequency of top 10 words\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.tokenize import word_tokenize# Passing the string text into word tokenize for breaking the sentences\n",
        "nltk.download('punkt')\n",
        "sen1=\"This is a NLP class and learn the topic very nicely and become a succesfully\"\n",
        "token = word_tokenize(sen1)\n",
        "fdist = FreqDist(token)\n",
        "fdist1 = fdist.most_common(10)\n",
        "fdist1\n",
        "# Top 10 word occurences."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8b6cIYMlYl_",
        "outputId": "5ed75b78-7fc9-4cb7-e52c-8f24bbe2bd58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2),\n",
              " ('and', 2),\n",
              " ('This', 1),\n",
              " ('is', 1),\n",
              " ('NLP', 1),\n",
              " ('class', 1),\n",
              " ('learn', 1),\n",
              " ('the', 1),\n",
              " ('topic', 1),\n",
              " ('very', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU35YPWPY7n8"
      },
      "source": [
        "#https://drive.google.com/file/d/1HV1sSIlxoAMfwuU1TahnZe2BXmIFjROp/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUkFZeBTcBUC"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1HV1sSIlxoAMfwuU1TahnZe2BXmIFjROp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4enARK7sYNqY",
        "outputId": "a65cc222-a763-4eda-bbad-a40f3e15d546"
      },
      "source": [
        "gram=word_tokenize(sen1)\n",
        "gram"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'is',\n",
              " 'a',\n",
              " 'NLP',\n",
              " 'class',\n",
              " 'and',\n",
              " 'learn',\n",
              " 'the',\n",
              " 'topic',\n",
              " 'very',\n",
              " 'nicely',\n",
              " 'and',\n",
              " 'become',\n",
              " 'a',\n",
              " 'succesfully']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VEmoqk1c6M2",
        "outputId": "f5275670-358a-4457-b291-24c8082d87f1"
      },
      "source": [
        "list(nltk.bigrams(gram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'is'),\n",
              " ('is', 'a'),\n",
              " ('a', 'NLP'),\n",
              " ('NLP', 'class'),\n",
              " ('class', 'and'),\n",
              " ('and', 'learn'),\n",
              " ('learn', 'the'),\n",
              " ('the', 'topic'),\n",
              " ('topic', 'very'),\n",
              " ('very', 'nicely'),\n",
              " ('nicely', 'and'),\n",
              " ('and', 'become'),\n",
              " ('become', 'a'),\n",
              " ('a', 'succesfully')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsL2I63_dM5V",
        "outputId": "8748e1ce-2386-4bad-f826-37d4079d707c"
      },
      "source": [
        "list(nltk.trigrams(gram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'is', 'a'),\n",
              " ('is', 'a', 'NLP'),\n",
              " ('a', 'NLP', 'class'),\n",
              " ('NLP', 'class', 'and'),\n",
              " ('class', 'and', 'learn'),\n",
              " ('and', 'learn', 'the'),\n",
              " ('learn', 'the', 'topic'),\n",
              " ('the', 'topic', 'very'),\n",
              " ('topic', 'very', 'nicely'),\n",
              " ('very', 'nicely', 'and'),\n",
              " ('nicely', 'and', 'become'),\n",
              " ('and', 'become', 'a'),\n",
              " ('become', 'a', 'succesfully')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5i7AgxddmBN",
        "outputId": "6d835384-fdcc-4ed6-a9f5-61a8a1275c51"
      },
      "source": [
        "list(nltk.ngrams(gram,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'is', 'a', 'NLP', 'class'),\n",
              " ('is', 'a', 'NLP', 'class', 'and'),\n",
              " ('a', 'NLP', 'class', 'and', 'learn'),\n",
              " ('NLP', 'class', 'and', 'learn', 'the'),\n",
              " ('class', 'and', 'learn', 'the', 'topic'),\n",
              " ('and', 'learn', 'the', 'topic', 'very'),\n",
              " ('learn', 'the', 'topic', 'very', 'nicely'),\n",
              " ('the', 'topic', 'very', 'nicely', 'and'),\n",
              " ('topic', 'very', 'nicely', 'and', 'become'),\n",
              " ('very', 'nicely', 'and', 'become', 'a'),\n",
              " ('nicely', 'and', 'become', 'a', 'succesfully')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0m58VneYe6"
      },
      "source": [
        "#https://drive.google.com/file/d/1MKbFFcnsuNKHKoTEQpPSM8J59StvImo7/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP2M71IQebuV"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1MKbFFcnsuNKHKoTEQpPSM8J59StvImo7)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYsjK9gWdQcw"
      },
      "source": [
        "#steming- CAN OR CAN NOT HAVE A MEANING.\n",
        "from nltk.stem import PorterStemmer\n",
        "pst=PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWkmskI-dZ_o",
        "outputId": "82848213-0a08-408c-b4af-98dcde03c679"
      },
      "source": [
        "print(pst.stem(\"Buying\")); \n",
        "print(pst.stem(\"Giving\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buy\n",
            "give\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pst.stem('studies'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7mSP8d-eTPs",
        "outputId": "8a6f635f-a4f8-4c1f-9fb7-cf01cc6bd901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "studi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pst.stem('dancings'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO3UBebRf8qm",
        "outputId": "a765548d-7a47-442d-9678-604c50468e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "danc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XtFLn3esU1"
      },
      "source": [
        "#https://drive.google.com/file/d/1_J1VC2agRFH-W-2T6_ouMw0zos0_jU7L/view?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1-TBlNxAUIE55x4y-YF6eLKBIuqcYWiLN)"
      ],
      "metadata": {
        "id": "xnnQhK82s_PQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mAKxQvefCoC"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=1_J1VC2agRFH-W-2T6_ouMw0zos0_jU7L)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPKQS_rygMsl",
        "outputId": "35830470-ab3f-4d84-e2ee-5a25b1f62a49"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62VoXBRIfIey"
      },
      "source": [
        "# LEMMATISATION - SHORT WORD AFTER OPERATION MUST HAVE A MEANING.\n",
        "from nltk.stem import wordnet,WordNetLemmatizer\n",
        "lem1=WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWY1YOf3fqFz"
      },
      "source": [
        "word2=[\"raining\", \"dancings\",\"washing\",\"cook\",\"studies\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWagpTSff2_L",
        "outputId": "efa0731e-6680-4f45-eda7-2e22b0df4d9f"
      },
      "source": [
        "for i in word2:\n",
        "  print(i+\"---\"+lem1.lemmatize(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raining---raining\n",
            "dancings---dancing\n",
            "washing---washing\n",
            "cook---cook\n",
            "studies---study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXlzzNNhf8WB"
      },
      "source": [
        "# Noun pronoun verb preposition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6TjyfbXv7b2",
        "outputId": "33581d68-fcbd-4a4b-f6c4-2bd0aa498698"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eDf82EGvYtK",
        "outputId": "41e477de-931f-40f6-f6e8-6edb53b0d2a7"
      },
      "source": [
        "for i in sen1_token:\n",
        "  print(nltk.pos_tag([i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'DT')]\n",
            "[('is', 'VBZ')]\n",
            "[('a', 'DT')]\n",
            "[('NLP', 'NN')]\n",
            "[('class', 'NN')]\n",
            "[('and', 'CC')]\n",
            "[('learn', 'NN')]\n",
            "[('the', 'DT')]\n",
            "[('topic', 'NN')]\n",
            "[('very', 'RB')]\n",
            "[('nicely', 'RB')]\n",
            "[('and', 'CC')]\n",
            "[('become', 'NN')]\n",
            "[('a', 'DT')]\n",
            "[('succesfully', 'RB')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyNrul9Uxjv-",
        "outputId": "a88cec99-563d-4655-ec85-030a3816cddc"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfB7PxiWx047"
      },
      "source": [
        "sen2=\"Google is the best company to work and Robin work here\"\n",
        "sen2_token=word_tokenize(sen2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fruYEIf_xWS3",
        "outputId": "1575919e-3b3f-4192-c759-a793458798ee"
      },
      "source": [
        "tags=nltk.pos_tag(sen2_token)\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVH1FlNIxgPj"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "-iaGFHP4vp5r",
        "outputId": "56ec083d-eb67-4ecb-9680-ee805a33b467"
      },
      "source": [
        "#Stopwords- most common words use in languages such as : a, the, an etc\n",
        "# importing stopwords from nltk library\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "common_eng_words = set(stopwords.words('english'))\n",
        "print(\"english common words:\\n\",common_eng_words)\n",
        "\n",
        "text =\"Cristiano Ronaldo was born on February 5, 1985, in Funchal, Madeira, Portugal.\"\n",
        "print(\"orignal text:\\n\",text)\n",
        "text1 = word_tokenize(text.lower())\n",
        "print(\"text1:\\n\",text1);\n",
        "\n",
        "stopwords = [x for x in text1 if x not in common_eng_words]\n",
        "print(\"stopwords:\\n\",stopwords)\n",
        "\n",
        "'''\n",
        "stopwords remove the common english words from sentences.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "orignal text:\n",
            " Cristiano Ronaldo was born on February 5, 1985, in Funchal, Madeira, Portugal.\n",
            "text1:\n",
            " ['cristiano', 'ronaldo', 'was', 'born', 'on', 'february', '5', ',', '1985', ',', 'in', 'funchal', ',', 'madeira', ',', 'portugal', '.']\n",
            "english common words:\n",
            " {'y', 'himself', 'did', 'through', \"hadn't\", 'itself', 'themselves', 'most', 'll', 'yours', 'didn', 'you', 'before', 'her', 'what', 'up', 'down', 'wouldn', 'of', 'about', 'wasn', \"shan't\", 'a', \"should've\", 'very', 'hers', 'too', 'd', 'as', 'couldn', \"shouldn't\", 'that', \"wasn't\", 'such', 'both', 'am', 'above', 'at', 'for', 'from', 'until', 'after', 'doesn', 'an', \"wouldn't\", 'on', 'he', 'or', 'whom', 'against', \"she's\", 'shan', 'and', 'my', 'were', 'our', 'again', \"needn't\", 'i', 'only', 'they', \"won't\", 'o', 'had', 'into', 'once', 'm', \"you'll\", \"hasn't\", \"doesn't\", 'some', 'not', 'over', 'was', 'so', 'doing', 'its', 'won', \"couldn't\", \"mustn't\", 'than', 'if', 'when', \"don't\", 'do', 'yourself', 'it', 'hadn', 'isn', \"you'd\", 'other', \"you've\", 'nor', \"haven't\", 'theirs', 'she', 'be', 'does', 'because', 'those', 'don', 'all', 'me', \"that'll\", 'during', 'under', 'the', 'any', 'these', 'own', 'should', 'hasn', 'who', 'ain', 's', 'further', 'him', 'no', 'herself', 'their', 'myself', 'to', 'here', 'where', 'has', 'being', 'is', \"aren't\", 'which', 'just', \"mightn't\", \"weren't\", 'between', \"it's\", 'ma', \"isn't\", 'now', \"you're\", 'been', 'mustn', 'having', 'will', 'weren', 'but', 'we', 'this', 'are', 'haven', 'your', 'there', 'below', 'can', 'few', 'off', \"didn't\", 'same', 'shouldn', 've', 'out', 'have', 'in', 'yourselves', 'each', 't', 'them', 'aren', 'by', 'mightn', 'how', 'why', 'his', 'with', 'more', 'then', 'needn', 'while', 'ours', 're', 'ourselves'}\n",
            "stopwords:\n",
            " ['cristiano', 'ronaldo', 'born', 'february', '5', ',', '1985', ',', 'funchal', ',', 'madeira', ',', 'portugal', '.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nstopwords remove the common english words from sentences.\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#POS\n",
        "sen1=\"Hi this is the world of great possibilities and we just have to achieve those goals.\"\n",
        "word1=word_tokenize(sen1)\n",
        "for w in word1:\n",
        "  print(nltk.pos_tag([w]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFXSwzWkfP1H",
        "outputId": "c7a3195f-62f8-4948-edec-37a433902f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hi', 'NN')]\n",
            "[('this', 'DT')]\n",
            "[('is', 'VBZ')]\n",
            "[('the', 'DT')]\n",
            "[('world', 'NN')]\n",
            "[('of', 'IN')]\n",
            "[('great', 'JJ')]\n",
            "[('possibilities', 'NNS')]\n",
            "[('and', 'CC')]\n",
            "[('we', 'PRP')]\n",
            "[('just', 'RB')]\n",
            "[('have', 'VB')]\n",
            "[('to', 'TO')]\n",
            "[('achieve', 'NN')]\n",
            "[('those', 'DT')]\n",
            "[('goals', 'NNS')]\n",
            "[('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# named entity recognization.\n",
        "from nltk import ne_chunk# tokenize and POS Tagging before doing chunk\n",
        "text = \"Google's CEO Sundar Pichai introduced the new Pixel at Minnesota Roi Centre Event\"#importing chunk library from nltk\n",
        "tok=word_tokenize(text)\n",
        "tag=nltk.pos_tag(tok)\n",
        "chunk=ne_chunk(tag)\n",
        "print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZloDBTxv4YZc",
        "outputId": "6c613292-c449-49e5-e527-0feb6d3b2ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (GPE Google/NNP)\n",
            "  's/POS\n",
            "  (ORGANIZATION CEO/NNP Sundar/NNP Pichai/NNP)\n",
            "  introduced/VBD\n",
            "  the/DT\n",
            "  new/JJ\n",
            "  Pixel/NNP\n",
            "  at/IN\n",
            "  (ORGANIZATION Minnesota/NNP Roi/NNP Centre/NNP)\n",
            "  Event/NNP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text=\"Hi this is always a great moment, we will be together forever\"\n",
        "tok2=word_tokenize(text)\n",
        "tags=nltk.pos_tag(tok2)\n",
        "reg=\"NP:{<DT>?<JJ>*<NN>}\"\n",
        "a=nltk.RegexpParser(reg)\n",
        "result=a.parse(tags)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7V-MnG35QkG",
        "outputId": "7d5c7b32-b373-4230-9e08-de84b0d54c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  Hi/NNP\n",
            "  this/DT\n",
            "  is/VBZ\n",
            "  always/RB\n",
            "  (NP a/DT great/JJ moment/NN)\n",
            "  ,/,\n",
            "  we/PRP\n",
            "  will/MD\n",
            "  be/VB\n",
            "  together/RB\n",
            "  forever/RB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hBu8T96r9DtP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}